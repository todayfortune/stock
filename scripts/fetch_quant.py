import os
import json
import pandas as pd
import numpy as np
import FinanceDataReader as fdr
from pykrx import stock
from datetime import datetime, timedelta

# ---------------------------------------------------------
# 1. ì„¤ì • ë° ì´ˆê¸°í™”
# ---------------------------------------------------------
def find_repo_root(start_path: str) -> str:
    p = os.path.abspath(start_path)
    while True:
        if os.path.isdir(os.path.join(p, "data")): return p
        parent = os.path.dirname(p)
        if parent == p: return os.path.dirname(os.path.abspath(start_path))
        p = parent

HERE = os.path.dirname(os.path.abspath(__file__))
BASE_DIR = find_repo_root(HERE)
DATA_DIR = os.path.join(BASE_DIR, "data")
THEME_MAP_FILE = os.path.join(BASE_DIR, 'scripts', 'theme_map.json') # í…Œë§ˆë§µ ë¡œë“œ ì¶”ê°€

os.makedirs(DATA_DIR, exist_ok=True)

def load_theme_map():
    if os.path.exists(THEME_MAP_FILE):
        with open(THEME_MAP_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

# ---------------------------------------------------------
# 2. ë°ì´í„° ìˆ˜ì§‘ ì—”ì§„
# ---------------------------------------------------------
def get_fundamental_data():
    """pykrxë¡œ íŽ€ë”ë©˜í„¸ ë°ì´í„° ìˆ˜ì§‘"""
    date = datetime.now()
    for i in range(7):
        d_str = date.strftime("%Y%m%d")
        try:
            print(f"   Trying fundamentals for {d_str}...")
            df = stock.get_market_fundamental_by_ticker(d_str, market="ALL")
            if not df.empty:
                print(f"   âœ… Found fundamentals.")
                return df
        except: pass
        date -= timedelta(days=1)
    return None

def get_sector_data():
    """
    [í•µì‹¬ ìˆ˜ì •] KOSPI/KOSDAQ ê°œë³„ í˜¸ì¶œë¡œ ì„¹í„° ì •ë³´ í™•ë³´
    """
    print("   Fetching Sector info (Separately)...")
    try:
        # ê°ê° ê°€ì ¸ì™€ì•¼ Sector ì»¬ëŸ¼ì´ ì‚´ì•„ìžˆìŒ
        k = fdr.StockListing('KOSPI')
        q = fdr.StockListing('KOSDAQ')
        
        # êµ¬ë¶„ìž ì¶”ê°€
        k['Market_Type'] = 'KOSPI'
        q['Market_Type'] = 'KOSDAQ'
        
        df = pd.concat([k, q])
        return df
    except Exception as e:
        print(f"   âš ï¸ Sector Fetch Error: {e}")
        return pd.DataFrame()

def run_quant_analysis():
    print("ðŸ§ª Running Quant Analysis (Sector Fix v1.6)...")
    
    # 1. íŽ€ë”ë©˜í„¸ ë°ì´í„°
    df_fund = get_fundamental_data()
    if df_fund is None:
        print("âŒ Fund data missing.")
        return
    df_fund = df_fund.reset_index().rename(columns={'í‹°ì»¤': 'Code'})

    # 2. ì—…ì¢… ë°ì´í„°
    df_master = get_sector_data()
    
    # ì»¬ëŸ¼ëª… í‘œì¤€í™” (í•œê¸€/ì˜ì–´ ëª¨ë‘ Sectorë¡œ)
    col_map = {
        'Symbol': 'Code', 'ì¢…ëª©ì½”ë“œ': 'Code', 'Name': 'Name', 'ì¢…ëª©ëª…': 'Name',
        'Sector': 'Sector', 'Industry': 'Sector', 'Wics': 'Sector', 'ì—…ì¢…': 'Sector', 'ì—…ì¢…ëª…': 'Sector'
    }
    df_master = df_master.rename(columns=col_map)

    # 3. ë°ì´í„° ë³‘í•©
    print("   Merging Data...")
    df = pd.merge(df_master, df_fund, on='Code', how='inner')

    # ---------------------------------------------------------
    # [Fix] ì„¹í„° ë¶„ë¥˜ ë¡œì§ ê°•í™”
    # ---------------------------------------------------------
    # 1. 'Unknown' ì²˜ë¦¬ëœ ê²ƒë“¤ ë³µêµ¬ ì‹œë„
    if 'Sector' not in df.columns:
        df['Sector'] = 'ê¸°íƒ€'
    
    df['Sector'] = df['Sector'].fillna('ê¸°íƒ€')

    # 2. Theme Map ì˜¤ë²„ë¼ì´ë“œ (ìš°ë¦¬ê°€ ì •í•œ í…Œë§ˆê°€ ìµœìš°ì„ )
    theme_map = load_theme_map()
    print(f"   Applying {len(theme_map)} custom themes...")
    
    for code, custom_sector in theme_map.items():
        if code in df['Code'].values:
            # í•´ë‹¹ ì¢…ëª©ì˜ Sectorë¥¼ ì»¤ìŠ¤í…€ í…Œë§ˆë¡œ ê°•ì œ ë³€ê²½
            df.loc[df['Code'] == code, 'Sector'] = custom_sector

    # 3. ì£¼ìš” ì˜ì–´ ì„¹í„°ëª… í•œê¸€ ë³€í™˜ (ë³´ê¸° ì¢‹ê²Œ)
    sector_translate = {
        'IT': 'IT/ì „ê¸°ì „ìž', 'Finance': 'ê¸ˆìœµ', 'Health Care': 'ë°”ì´ì˜¤/í—¬ìŠ¤ì¼€ì–´',
        'Energy': 'ì—ë„ˆì§€', 'Materials': 'ì†Œìž¬/í™”í•™', 'Industrials': 'ì‚°ì—…ìž¬/ê¸°ê³„',
        'Consumer Discretionary': 'ê²½ê¸°ì†Œë¹„ìž¬', 'Consumer Staples': 'í•„ìˆ˜ì†Œë¹„ìž¬',
        'Utilities': 'ìœ í‹¸ë¦¬í‹°', 'Telecommunication Services': 'í†µì‹ '
    }
    df['Sector'] = df['Sector'].replace(sector_translate)

    # ---------------------------------------------------------

    # 4. ë°ì´í„° ì •ì œ
    if 'PBR' in df.columns: df['PBR'] = pd.to_numeric(df['PBR'], errors='coerce')
    if 'PER' in df.columns: df['PER'] = pd.to_numeric(df['PER'], errors='coerce')
    
    df = df[(df['PBR'] > 0) & (df['PER'] > 0)].copy()
    df['ROE'] = (df['PBR'] / df['PER']) * 100
    df = df[(df['ROE'] > 0) & (df['ROE'] < 60) & (df['PBR'] < 15)]
    
    # 5. ë¶„ì„ ë° ì €ìž¥
    quant_data = {}
    print(f"   Analyzing {len(df)} stocks...")

    for sector, group in df.groupby('Sector'):
        # ì¢…ëª© ìˆ˜ ë„ˆë¬´ ì ê±°ë‚˜ 'ê¸°íƒ€' ì„¹í„°ëŠ” ì œì™¸
        if len(group) < 5 or sector == 'ê¸°íƒ€': continue 
        
        x = group['ROE'].values
        y = group['PBR'].values
        
        try:
            slope, intercept = np.polyfit(x, y, 1)
        except: continue
        
        group['PBR_Expected'] = slope * group['ROE'] + intercept
        group['Residual'] = group['PBR'] - group['PBR_Expected']
        
        items = []
        for _, row in group.iterrows():
            items.append({
                'code': row['Code'],
                'name': row['Name'],
                'pbr': round(row['PBR'], 2),
                'roe': round(row['ROE'], 2),
                'residual': round(row['Residual'], 3),
                'is_undervalued': bool(row['Residual'] < 0)
            })
            
        items.sort(key=lambda k: k['residual'])
        quant_data[sector] = { 'slope': slope, 'intercept': intercept, 'items': items }

    # ì €ìž¥
    output_path = os.path.join(DATA_DIR, 'quant_stats.json')
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(quant_data, f, ensure_ascii=False, indent=2)
        
    print(f"âœ… Quant Analysis Done (Saved {len(quant_data)} sectors).")

if __name__ == "__main__":
    run_quant_analysis()
