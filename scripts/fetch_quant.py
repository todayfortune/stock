import os
import json
import pandas as pd
import numpy as np
import FinanceDataReader as fdr
from pykrx import stock
from datetime import datetime, timedelta

# ---------------------------------------------------------
# 1. ÏÑ§Ï†ï Î∞è Ïú†Ìã∏Î¶¨Ìã∞
# ---------------------------------------------------------
def find_repo_root(start_path: str) -> str:
    # [Bug Fix #2] Î¨¥Ìïú Î£®ÌîÑ Î∞©ÏßÄ (ÏµúÎåÄ 10Îã®Í≥ÑÎßå ÌÉêÏÉâ)
    p = os.path.abspath(start_path)
    for _ in range(10):
        if os.path.isdir(os.path.join(p, "data")): return p
        parent = os.path.dirname(p)
        if parent == p: break
        p = parent
    return os.path.dirname(os.path.abspath(start_path)) # Î™ª Ï∞æÏúºÎ©¥ ÌòÑÏû¨ ÏúÑÏπò Î∞òÌôò

HERE = os.path.dirname(os.path.abspath(__file__))
BASE_DIR = find_repo_root(HERE)
DATA_DIR = os.path.join(BASE_DIR, "data")
THEME_MAP_FILE = os.path.join(BASE_DIR, 'scripts', 'theme_map.json')
os.makedirs(DATA_DIR, exist_ok=True)

def load_theme_map():
    if os.path.exists(THEME_MAP_FILE):
        try:
            with open(THEME_MAP_FILE, 'r', encoding='utf-8') as f: return json.load(f)
        except Exception as e:
            print(f"‚ö†Ô∏è Theme Map Load Failed: {e}")
            return {}
    return {}

# ---------------------------------------------------------
# 2. ÏÑπÌÑ∞ Ï†ïÎ¶¨ Ìï®Ïàò (Ïö∞ÏÑ†ÏàúÏúÑ Î°úÏßÅ Í∞ïÌôî)
# ---------------------------------------------------------
def clean_sector_name(raw_sector):
    if pd.isna(raw_sector): return "Í∏∞ÌÉÄ"
    s = str(raw_sector).replace(' ', '')

    # [Bug Fix #8] Îß§Ìïë Ïò§ÌÉê Î∞©ÏßÄ (Î¶¨Ïä§Ìä∏ ÏàúÏÑúÎåÄÎ°ú Ïö∞ÏÑ†ÏàúÏúÑ Ï†ÅÏö©)
    # Í∏¥ Îã®Ïñ¥Î∂ÄÌÑ∞ Î®ºÏ†Ä Îß§Ïπ≠Ìï¥Ïïº Ï†ïÌôïÎèÑÍ∞Ä ÎÜíÏùå (Ïòà: 'Ï†ÑÍ∏∞Ï†ÑÏûê' vs 'Ï†ÑÍ∏∞')
    keyword_order = [
        (['Ï†úÏïΩ', 'ÏùòÏïΩ', 'Î∞îÏù¥Ïò§', 'ÏùòÎ£å'], 'Ï†úÏïΩ/Î∞îÏù¥Ïò§'),
        (['Î∞òÎèÑÏ≤¥'], 'Î∞òÎèÑÏ≤¥/Ïû•ÎπÑ'),
        (['ÏÜåÌîÑÌä∏Ïõ®Ïñ¥', 'Í≤åÏûÑ', 'Ï†ïÎ≥¥ÏÑúÎπÑÏä§', 'Ïù∏ÌÑ∞ÎÑ∑', 'ÎîîÏßÄÌÑ∏'], 'SW/Í≤åÏûÑ/Ïù∏ÌÑ∞ÎÑ∑'),
        (['ÏûêÎèôÏ∞®', 'Ìä∏Î†àÏùºÎü¨', 'Î™®ÎπåÎ¶¨Ìã∞'], 'ÏûêÎèôÏ∞®/Î∂ÄÌíà'),
        (['2Ï∞®Ï†ÑÏßÄ', 'Î∞∞ÌÑ∞Î¶¨', 'ÏóêÎÑàÏßÄÏÜîÎ£®ÏÖò'], '2Ï∞®Ï†ÑÏßÄ'),
        (['ÌôîÌïô', 'ÏÑùÏú†', 'Í≥†Î¨¥', 'ÌîåÎùºÏä§Ìã±'], 'ÌôîÌïô/Ï†ïÏú†'),
        (['Ï≤†Í∞ï', 'Í∏àÏÜç', 'ÏïåÎ£®ÎØ∏ÎäÑ', 'Í¥ëÎ¨º'], 'Ï≤†Í∞ï/ÏÜåÏû¨'),
        (['Í∏∞Í≥Ñ', 'ÏóîÏßÑ', 'Ïû•ÎπÑ'], 'Í∏∞Í≥Ñ/Ïû•ÎπÑ'),
        (['Í±¥ÏÑ§', 'ÌÜ†Î™©', 'Í±¥Ï∂ï', 'ÏóîÏßÄÎãàÏñ¥ÎßÅ'], 'Í±¥ÏÑ§/ÏóîÏßÄÎãàÏñ¥ÎßÅ'),
        (['Ï†ÑÍ∏∞', 'Ï†ÑÏûê', 'ÌÜµÏã†', 'Î∞©ÏÜ°', 'ÎîîÏä§ÌîåÎ†àÏù¥'], 'IT/Ï†ÑÍ∏∞Ï†ÑÏûê'),
        (['Í∏àÏúµ', 'ÏùÄÌñâ', 'Î≥¥Ìóò', 'Ï¶ùÍ∂å', 'ÏßÄÏ£º', 'Ìà¨Ïûê'], 'Í∏àÏúµ/ÏßÄÏ£º'),
        (['ÏãùÎ£åÌíà', 'ÏùåÎ£å', 'ÏùåÏãù'], 'ÏùåÏãùÎ£å'),
        (['Ïú†ÌÜµ', 'ÎèÑÎß§', 'ÏÜåÎß§', 'Î∞±ÌôîÏ†ê', 'ÏÉÅÏÇ¨'], 'Ïú†ÌÜµ/ÏÉÅÏÇ¨'),
        (['Ïö¥ÏÜ°', 'Ìï≠Í≥µ', 'Ï∞ΩÍ≥†', 'Ìï¥Ïö¥', 'Î¨ºÎ•ò'], 'Ïö¥ÏÜ°/Î¨ºÎ•ò'),
        (['ÏÑ¨Ïú†', 'ÏùòÎ≥µ', 'ÏùòÎ•ò', 'Ìå®ÏÖò'], 'ÏùòÎ•ò/ÏÑ¨Ïú†'),
        (['Ï¢ÖÏù¥', 'ÌéÑÌîÑ', 'Î™©Ïû¨'], 'Ï†úÏßÄ/Î™©Ïû¨'),
        (['Ï°∞ÏÑ†', 'Ï§ëÍ≥µÏóÖ'], 'Ï°∞ÏÑ†/Ï§ëÍ≥µÏóÖ'),
        (['ÏÑúÎπÑÏä§'], 'ÏÑúÎπÑÏä§ÏóÖ'),
    ]

    for keywords, sector in keyword_order:
        if any(k in s for k in keywords):
            return sector
    
    if 'Ï†úÏ°∞' in s: return 'Í∏∞ÌÉÄÏ†úÏ°∞'
    return 'Í∏∞ÌÉÄ'

# ---------------------------------------------------------
# 3. Îç∞Ïù¥ÌÑ∞ ÏàòÏßë
# ---------------------------------------------------------
def get_fundamental_data():
    date = datetime.now()
    for i in range(7):
        d_str = date.strftime("%Y%m%d")
        try:
            print(f"   Trying fundamentals for {d_str}...")
            df = stock.get_market_fundamental_by_ticker(d_str, market="ALL")
            if not df.empty:
                print(f"   ‚úÖ Found fundamentals for {d_str} ({len(df)} items)")
                return df
        # [Bug Fix #1] Íµ¨Ï≤¥Ï†ÅÏù∏ ÏóêÎü¨ Ï∂úÎ†•
        except Exception as e:
            print(f"   ‚ö†Ô∏è Failed for {d_str}: {e}")
            pass
        date -= timedelta(days=1)
    return None

def get_sector_data():
    print("   Fetching Sector info (KRX-DESC)...")
    try:
        df = fdr.StockListing('KRX-DESC')
        print(f"   ‚úÖ Sector info fetched ({len(df)} items)")
        return df
    except Exception as e:
        print(f"   ‚ùå Sector Fetch Error: {e}")
        return pd.DataFrame()

# ---------------------------------------------------------
# 4. Î©îÏù∏ Î∂ÑÏÑù Î°úÏßÅ
# ---------------------------------------------------------
def run_quant_analysis():
    print("üß™ Running Quant Analysis (Ultimate v3.0)...")
    
    # 1. Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Î∞è Ïú†Ìö®ÏÑ± Í≤ÄÏÇ¨
    df_fund = get_fundamental_data()
    # [Bug Fix #9] None Ï≤¥ÌÅ¨ Î™ÖÌôïÌôî
    if df_fund is None: 
        print("‚ùå Critical: No fundamental data found. Aborting.")
        return

    # [Bug Fix #3] Ïª¨ÎüºÎ™Ö ÌïòÎìúÏΩîÎî© Î∞©ÏßÄ (Ïú†Ïó∞Ìïú Ï≤òÎ¶¨)
    df_fund = df_fund.reset_index()
    ticker_col = None
    for col in ['Ìã∞Ïª§', 'Code', 'code', 'Symbol', 'symbol']:
        if col in df_fund.columns:
            ticker_col = col
            break
    
    if ticker_col:
        df_fund = df_fund.rename(columns={ticker_col: 'Code'})
    else:
        print(f"‚ùå Critical: Ticker column not found. Cols: {df_fund.columns}")
        return

    # Ï¢ÖÎ™©ÏΩîÎìú Î¨∏ÏûêÏó¥ ÌÜµÏùº ('005930')
    df_fund['Code'] = df_fund['Code'].astype(str).str.zfill(6)

    # 2. ÏÑπÌÑ∞ Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ
    df_master = get_sector_data()
    if df_master.empty:
        print("‚ùå Critical: No sector data found. Aborting.")
        return

    # Ïª¨Îüº ÌëúÏ§ÄÌôî
    rename_map = {
        'Symbol': 'Code', 'Code': 'Code', 
        'Name': 'Name', 'Sector': 'RawSector', 'ÏóÖÏ¢Ö': 'RawSector'
    }
    df_master = df_master.rename(columns=rename_map)
    
    # ÌïÑÏàò Ïª¨Îüº ÌôïÏù∏
    required_cols = ['Code', 'Name', 'RawSector']
    available_cols = [c for c in required_cols if c in df_master.columns]
    
    if 'RawSector' not in df_master.columns:
        print("‚ö†Ô∏è 'RawSector' column missing. Trying to fetch KOSPI/KOSDAQ separately...")
        # ÎπÑÏÉÅ ÎåÄÏ±Ö: Í∞úÎ≥Ñ Ìò∏Ï∂ú ÏãúÎèÑ
        try:
            k = fdr.StockListing('KOSPI'); q = fdr.StockListing('KOSDAQ')
            df_master = pd.concat([k, q]).rename(columns=rename_map)
        except: pass

    if 'RawSector' not in df_master.columns:
        print("‚ùå Sector column absolutely missing. Cannot proceed.")
        return

    df_master['Code'] = df_master['Code'].astype(str).str.zfill(6)

    # 3. Îç∞Ïù¥ÌÑ∞ Î≥ëÌï© & ÏÜêÏã§ Í≤ÄÏ¶ù
    print("   Merging Data...")
    before_count = len(df_master)
    
    # [Bug Fix #4] Îç∞Ïù¥ÌÑ∞ ÏÜêÏã§ Ï∂îÏ†Å
    df = pd.merge(df_master[['Code', 'Name', 'RawSector']], df_fund, on='Code', how='inner')
    after_count = len(df)
    print(f"   üìä Merge Status: {before_count} -> {after_count} stocks (Dropped: {before_count - after_count})")

    # 4. ÏÑπÌÑ∞ Îß§Ìïë Î∞è Ï†ïÎ¶¨
    df['Sector'] = df['RawSector'].apply(clean_sector_name)

    # Theme Map Ï†ÅÏö© (ÏÇ¨Ïö©Ïûê Ï†ïÏùò ÌÖåÎßà)
    theme_map = load_theme_map()
    print(f"   Applying {len(theme_map)} custom themes...")
    
    # [Bug Fix #5] ÌÉÄÏûÖ Î∂àÏùºÏπò Ìï¥Í≤∞ (str.zfill(6)Î°ú ÏñëÏ™Ω ÌÜµÏùº ÌõÑ ÎπÑÍµê)
    count_custom = 0
    for code, custom_sector in theme_map.items():
        code_str = str(code).zfill(6)
        mask = df['Code'] == code_str
        if mask.any():
            df.loc[mask, 'Sector'] = custom_sector
            count_custom += 1
    print(f"   üëâ Applied {count_custom} custom theme mappings.")

    # 5. Îç∞Ïù¥ÌÑ∞ Ï†ïÏ†ú (PBR/ROE)
    for col in ['PBR', 'PER']:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # [Bug Fix #6] ROE Í≥ÑÏÇ∞ ÏïàÏ†ÑÏÑ± (PER 0.01 ÎØ∏Îßå Ï†úÏô∏Î°ú Î¨¥ÌïúÎåÄ Î∞©ÏßÄ)
    df = df[(df['PBR'] > 0) & (df['PER'] > 0.01)].copy()
    df['ROE'] = (df['PBR'] / df['PER']) * 100
    
    # Ïù¥ÏÉÅÏπò Ï†úÍ±∞ (Ï∞®Ìä∏ ÏôúÍ≥° Î∞©ÏßÄ)
    df = df[(df['ROE'] > -20) & (df['ROE'] < 100) & (df['PBR'] < 20)]

    # 6. ÏÑπÌÑ∞Î≥Ñ Î∂ÑÏÑù Î∞è Ï†ÄÏû•
    quant_data = {}
    
    # 'Í∏∞ÌÉÄ' ÏÑπÌÑ∞Îäî Î∂ÑÏÑùÏóêÏÑú Ï†úÏô∏ (ÏÑ†ÌÉùÏ†Å)
    filtered_df = df[~df['Sector'].isin(['Í∏∞ÌÉÄ', 'Í∏∞ÌÉÄÏ†úÏ°∞'])]
    
    print(f"   Analyzing {len(filtered_df)} valid stocks...")
    success_count = 0

    for sector, group in filtered_df.groupby('Sector'):
        if len(group) < 5: continue 
        
        x = group['ROE'].values
        y = group['PBR'].values
        
        # [Bug Fix #7] ÌöåÍ∑ÄÎ∂ÑÏÑù Ïã§Ìå® Î°úÍ∑∏
        try:
            slope, intercept = np.polyfit(x, y, 1)
        except Exception as e:
            print(f"   ‚ö†Ô∏è Regression failed for {sector}: {e}")
            continue
        
        # ÏûîÏ∞® Í≥ÑÏÇ∞
        group = group.copy()
        group['PBR_Expected'] = slope * group['ROE'] + intercept
        group['Residual'] = group['PBR'] - group['PBR_Expected']
        
        items = []
        for _, row in group.iterrows():
            items.append({
                'code': row['Code'], 'name': row['Name'],
                'pbr': round(row['PBR'], 2), 'roe': round(row['ROE'], 2),
                'residual': round(row['Residual'], 3),
                'is_undervalued': bool(row['Residual'] < 0)
            })
        
        items.sort(key=lambda k: k['residual'])
        
        # [Bug Fix #10] JSON ÏßÅÎ†¨Ìôî ÏóêÎü¨ Ìï¥Í≤∞ (numpy type -> python float)
        quant_data[sector] = {
            'slope': float(slope),
            'intercept': float(intercept),
            'count': int(len(items)),
            'items': items
        }
        success_count += 1

    # ÏµúÏ¢Ö Ï†ÄÏû•
    try:
        with open(os.path.join(DATA_DIR, 'quant_stats.json'), 'w', encoding='utf-8') as f:
            json.dump(quant_data, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ Quant Analysis Completed. Saved {success_count} sectors.")
        print(f"   File path: {os.path.join(DATA_DIR, 'quant_stats.json')}")
    except Exception as e:
        print(f"‚ùå Final Save Error: {e}")

if __name__ == "__main__":
    run_quant_analysis()
